{"version":3,"sources":["../src/tokenization/grammar.ts","../src/tokenization/Lexer.ts","../src/Loom.ts"],"sourcesContent":["export default {\n    REGEX_IDENT: /\\p{L}/u,\n    REGEX_NUMBER: /\\d/,\n    REGEX_SYMBOL: /[.!?,;:()\\-+=%*\\\\/—–…${}><&#@°|]/,\n    REGEX_WHITESPACE: /\\s/,\n    REGEX_NEWLINE: /[\\n\\r]/,\n    REGEX_STRING_DELIMITER: /[\"']/,\n};","import grammar from './grammar';\nimport { LexMode, TokenStream, TokenType } from '../types/tokenization';\n\nexport default class Lexer {\n    /**\n     * The source code to tokenize\n     * @private\n     */\n    private source: string;\n\n    /**\n     * The current mode of lexing\n     * @private\n     */\n    private mode: LexMode = LexMode.ALL;\n\n    /**\n     * The current position of the cursor\n     * @private\n     */\n    private cursor: number = 0;\n\n    /**\n     * The position of the cursor at the start of the mode\n     * @private\n     */\n    private modeStartCursor: number = 0;\n\n    /**\n     * The current line, starting at line 1\n     * @private\n     */\n    private line: number = 1;\n\n    /**\n     * The current position on the current line, starting at 1\n     * @private\n     */\n    private column: number = 1;\n\n    /**\n     * The current character\n     * @private\n     */\n    private character: string = '';\n\n    /**\n     * The next character, handy for simple look-ahead\n     * @private\n     */\n    private nextCharacter: string = '';\n\n    /**\n     * The index of the last character, also the amount of characters\n     * @private\n     */\n    private end: number = 0;\n\n    /**\n     * The current token stream being created\n     * @private\n     */\n    private tokens: TokenStream = [];\n\n    /**\n     * The current value being lexed\n     * @private\n     */\n    private value: string = '';\n\n    /**\n     * The current delimiter (e.g. string delimiter or boundary)\n     * @private\n     */\n    private delimiter: string = ''\n\n    /**\n     * Transforms code into a TokenStream\n     * @param text\n     */\n    tokenize(text: string): TokenStream {\n\n        this.source = text;\n        this.end = this.source.length;\n\n        while (this.cursor < this.end) {\n\n            this.character = this.source[this.cursor];\n            this.nextCharacter = this.source[this.cursor+1] || null;\n\n            // Determine the mode\n            if (this.mode === LexMode.ALL) {\n                this.mode = this.determineMode();\n                this.modeStartCursor = this.cursor;\n            }\n\n            switch (this.mode) {\n                case LexMode.IDENT:\n                    this.lexIdent();\n                    break;\n                case LexMode.NUMBER:\n                    this.lexNumber();\n                    break;\n                case LexMode.SYMBOL:\n                    this.lexSymbol();\n                    break;\n                case LexMode.NEWLINE:\n                    this.lexNewline();\n                    break;\n                case LexMode.WHITESPACE:\n                    this.lexWhitespace();\n                    break;\n                case LexMode.UNKNOWN:\n                    this.lexUnknown();\n                    break;\n            }\n        }\n\n        return this.tokens;\n    }\n\n    /**\n     * @private\n     */\n    private atEnd(accountForDelimiter: boolean = false): boolean {\n        const offset = accountForDelimiter ? 1 : 0;\n        return this.cursor + offset >= this.end;\n    }\n\n    /**\n     * Determines the lexing mode based on the current character\n     * @private\n     */\n    private determineMode(): LexMode {\n\n        // Reset the current token value\n        this.value = '';\n\n        if (grammar.REGEX_IDENT.exec(this.character)) {\n            return LexMode.IDENT;\n        }\n\n        if (grammar.REGEX_STRING_DELIMITER.exec(this.character)) {\n            this.delimiter = this.character;\n            return LexMode.STRING;\n        }\n\n        if (grammar.REGEX_NUMBER.exec(this.character)) {\n            return LexMode.NUMBER;\n        }\n\n        if (grammar.REGEX_SYMBOL.exec(this.character)) {\n            return LexMode.SYMBOL;\n        }\n\n        if (grammar.REGEX_NEWLINE.exec(this.character)) {\n            return LexMode.NEWLINE;\n        }\n\n        if (grammar.REGEX_WHITESPACE.exec(this.character)) {\n            return LexMode.WHITESPACE;\n        }\n\n        return LexMode.UNKNOWN;\n    }\n\n    /**\n     * Tokenize identifier\n     * @private\n     */\n    private lexIdent() {\n\n        this.value += this.character;\n        this.cursor++;\n\n        if (! this.nextCharacter || ! grammar.REGEX_IDENT.exec(this.nextCharacter)) {\n            this.tokens.push({\n                type: TokenType.IDENT,\n                value: this.value,\n                line: this.line,\n                position: this.column,\n                end: this.atEnd(),\n            });\n            this.column += this.value.length;\n            this.mode = LexMode.ALL;\n        }\n    }\n\n    /**\n     * Tokenize number\n     * @private\n     */\n    private lexNumber() {\n        this.value += this.character;\n        this.cursor++;\n\n        if (!this.nextCharacter || !grammar.REGEX_NUMBER.exec(this.nextCharacter)) {\n            this.tokens.push({\n                type: TokenType.NUMBER,\n                value: this.value,\n                line: this.line,\n                position: this.column,\n                end: this.atEnd(),\n            });\n            this.column += this.cursor - this.modeStartCursor;\n            this.mode = LexMode.ALL;\n        }\n    }\n\n    /**\n     * Tokenize symbol\n     * @private\n     */\n    private lexSymbol() {\n\n        this.cursor++;\n\n        this.tokens.push({\n            type: TokenType.SYMBOL,\n            value: this.character,\n            line: this.line,\n            position: this.column,\n            end: this.atEnd(),\n        });\n        this.column++;\n        this.mode = LexMode.ALL;\n    }\n\n    /**\n     * Tokenize newline\n     * @private\n     */\n    private lexNewline() {\n        this.cursor++;\n        this.line++;\n        this.column = 1;\n        this.mode = LexMode.ALL;\n    }\n\n    /**\n     * Tokenize whitespace\n     * @private\n     */\n    private lexWhitespace() {\n        this.cursor++;\n        this.column++;\n        this.mode = LexMode.ALL;\n    }\n\n    /**\n     * Tokenize unknown\n     * @private\n     */\n    private lexUnknown() {\n        this.tokens.push({\n            type: TokenType.UNKNOWN,\n            value: this.character,\n            line: this.line,\n            position: this.column,\n            end: this.atEnd(),\n        });\n        this.cursor++;\n        this.column++;\n        this.mode = LexMode.ALL;\n    }\n}","import Lexer from './tokenization/Lexer';\n\nexport default class Loom {\n    /**\n     *\n     * @param code\n     */\n    public static make(code: string): string {\n        const tokens = (new Lexer()).tokenize(code);\n        /*\n        const ast = (new Parser().parse(tokens));\n\n        console.log(ast.getChildren()[0].getChildren());*/\n\n        // Simple compiling\n        const output = [];\n\n        tokens.forEach(token => {\n            output.push(`${token.type}(${token.value})`);\n        });\n\n        return output.join('\\n');\n    }\n}"],"mappings":";AAAA,IAAO,kBAAQ;AAAA,EACX,aAAa;AAAA,EACb,cAAc;AAAA,EACd,cAAc;AAAA,EACd,kBAAkB;AAAA,EAClB,eAAe;AAAA,EACf,wBAAwB;AAC5B;;;ACJA,IAAqB,QAArB,MAA2B;AAAA,EAA3B;AAWI;AAAA;AAAA;AAAA;AAAA,SAAQ;AAMR;AAAA;AAAA;AAAA;AAAA,SAAQ,SAAiB;AAMzB;AAAA;AAAA;AAAA;AAAA,SAAQ,kBAA0B;AAMlC;AAAA;AAAA;AAAA;AAAA,SAAQ,OAAe;AAMvB;AAAA;AAAA;AAAA;AAAA,SAAQ,SAAiB;AAMzB;AAAA;AAAA;AAAA;AAAA,SAAQ,YAAoB;AAM5B;AAAA;AAAA;AAAA;AAAA,SAAQ,gBAAwB;AAMhC;AAAA;AAAA;AAAA;AAAA,SAAQ,MAAc;AAMtB;AAAA;AAAA;AAAA;AAAA,SAAQ,SAAsB,CAAC;AAM/B;AAAA;AAAA;AAAA;AAAA,SAAQ,QAAgB;AAMxB;AAAA;AAAA;AAAA;AAAA,SAAQ,YAAoB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAM5B,SAAS,MAA2B;AAEhC,SAAK,SAAS;AACd,SAAK,MAAM,KAAK,OAAO;AAEvB,WAAO,KAAK,SAAS,KAAK,KAAK;AAE3B,WAAK,YAAY,KAAK,OAAO,KAAK,MAAM;AACxC,WAAK,gBAAgB,KAAK,OAAO,KAAK,SAAO,CAAC,KAAK;AAGnD,UAAI,KAAK,sBAAsB;AAC3B,aAAK,OAAO,KAAK,cAAc;AAC/B,aAAK,kBAAkB,KAAK;AAAA,MAChC;AAEA,cAAQ,KAAK,MAAM;AAAA,QACf;AACI,eAAK,SAAS;AACd;AAAA,QACJ;AACI,eAAK,UAAU;AACf;AAAA,QACJ;AACI,eAAK,UAAU;AACf;AAAA,QACJ;AACI,eAAK,WAAW;AAChB;AAAA,QACJ;AACI,eAAK,cAAc;AACnB;AAAA,QACJ;AACI,eAAK,WAAW;AAChB;AAAA,MACR;AAAA,IACJ;AAEA,WAAO,KAAK;AAAA,EAChB;AAAA;AAAA;AAAA;AAAA,EAKQ,MAAM,sBAA+B,OAAgB;AACzD,UAAM,SAAS,sBAAsB,IAAI;AACzC,WAAO,KAAK,SAAS,UAAU,KAAK;AAAA,EACxC;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,gBAAyB;AAG7B,SAAK,QAAQ;AAEb,QAAI,gBAAQ,YAAY,KAAK,KAAK,SAAS,GAAG;AAC1C;AAAA,IACJ;AAEA,QAAI,gBAAQ,uBAAuB,KAAK,KAAK,SAAS,GAAG;AACrD,WAAK,YAAY,KAAK;AACtB;AAAA,IACJ;AAEA,QAAI,gBAAQ,aAAa,KAAK,KAAK,SAAS,GAAG;AAC3C;AAAA,IACJ;AAEA,QAAI,gBAAQ,aAAa,KAAK,KAAK,SAAS,GAAG;AAC3C;AAAA,IACJ;AAEA,QAAI,gBAAQ,cAAc,KAAK,KAAK,SAAS,GAAG;AAC5C;AAAA,IACJ;AAEA,QAAI,gBAAQ,iBAAiB,KAAK,KAAK,SAAS,GAAG;AAC/C;AAAA,IACJ;AAEA;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,WAAW;AAEf,SAAK,SAAS,KAAK;AACnB,SAAK;AAEL,QAAI,CAAE,KAAK,iBAAiB,CAAE,gBAAQ,YAAY,KAAK,KAAK,aAAa,GAAG;AACxE,WAAK,OAAO,KAAK;AAAA,QACb;AAAA,QACA,OAAO,KAAK;AAAA,QACZ,MAAM,KAAK;AAAA,QACX,UAAU,KAAK;AAAA,QACf,KAAK,KAAK,MAAM;AAAA,MACpB,CAAC;AACD,WAAK,UAAU,KAAK,MAAM;AAC1B,WAAK;AAAA,IACT;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,YAAY;AAChB,SAAK,SAAS,KAAK;AACnB,SAAK;AAEL,QAAI,CAAC,KAAK,iBAAiB,CAAC,gBAAQ,aAAa,KAAK,KAAK,aAAa,GAAG;AACvE,WAAK,OAAO,KAAK;AAAA,QACb;AAAA,QACA,OAAO,KAAK;AAAA,QACZ,MAAM,KAAK;AAAA,QACX,UAAU,KAAK;AAAA,QACf,KAAK,KAAK,MAAM;AAAA,MACpB,CAAC;AACD,WAAK,UAAU,KAAK,SAAS,KAAK;AAClC,WAAK;AAAA,IACT;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,YAAY;AAEhB,SAAK;AAEL,SAAK,OAAO,KAAK;AAAA,MACb;AAAA,MACA,OAAO,KAAK;AAAA,MACZ,MAAM,KAAK;AAAA,MACX,UAAU,KAAK;AAAA,MACf,KAAK,KAAK,MAAM;AAAA,IACpB,CAAC;AACD,SAAK;AACL,SAAK;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,aAAa;AACjB,SAAK;AACL,SAAK;AACL,SAAK,SAAS;AACd,SAAK;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,gBAAgB;AACpB,SAAK;AACL,SAAK;AACL,SAAK;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,aAAa;AACjB,SAAK,OAAO,KAAK;AAAA,MACb;AAAA,MACA,OAAO,KAAK;AAAA,MACZ,MAAM,KAAK;AAAA,MACX,UAAU,KAAK;AAAA,MACf,KAAK,KAAK,MAAM;AAAA,IACpB,CAAC;AACD,SAAK;AACL,SAAK;AACL,SAAK;AAAA,EACT;AACJ;;;ACvQA,IAAqB,OAArB,MAA0B;AAAA;AAAA;AAAA;AAAA;AAAA,EAKtB,OAAc,KAAK,MAAsB;AACrC,UAAM,SAAU,IAAI,MAAM,EAAG,SAAS,IAAI;AAO1C,UAAM,SAAS,CAAC;AAEhB,WAAO,QAAQ,WAAS;AACpB,aAAO,KAAK,GAAG,MAAM,IAAI,IAAI,MAAM,KAAK,GAAG;AAAA,IAC/C,CAAC;AAED,WAAO,OAAO,KAAK,IAAI;AAAA,EAC3B;AACJ;","names":[]}